
Prognostic technologies are crucial in any modern day industry. With the increasing complexity of industrial machinery and wider availability of the historical sensor data, the demand for new prognostic methods is expanding. Both reliability and cost effectiveness concerns lead to a search for new methods to increase safety, extend the useful life of the equipment by providing timely and cost effective maintenance. 

The majority of existing techniques are based on statistics provided by equipment manufacturers, human expertise, and experience-based intuition. However, those techniques are based solely on historical data statistics and can address only a limited subset of root causes for which such statistics are estimated, leading to unexpected breakdown or failure. As a result conditional maintenance, as concept, draws more attention over the last years. In contrary to the scheduled preventive maintenance where corrective actions  are only dependent on time interval passed between them, conditional monitoring assigns actions based on the current state of equipment. In this regard, accurate estimation of the equipment condition is the main objective of the prognostic maintenance. As a result, such metrics as remaining useful life (RUL) and health index (HI) have been established as golden standard \cite{cerquitelli2021predictive} for assessing current state of the equipment. One of the advantages of employing data-driven methodologies for RUL estimation is that statistical methods and probabilistic models that apply to the given data without relying on the physics of the underlying degradation process can be used to estimate the RUL.

Predictive maintenance seeks correlations and patterns in order to predict and avert conditions that may reduce the operational lifetime of production equipment.
In real-world predictive maintenance scenarios, such as manufacturing or aviation, not only is correct estimation of RUL or HI vital, but so is the interpretability and transparency of the models used to estimate them, as crucial choices are dependent on their forecasts.



\section{Literature review}
\subsection{RUL Prediction}
In recent years, data-driven approaches have been widely applied to RUL prediction. The increased availability of training data, no prior knowledge of modeled physical systems requirements and fast implementation made them a popular choice in recent works.  Among them are classical machine learning methods, such as SVR, Decision Trees and Random Forest \cite{Wang2015, Sangram201887623}, which showed good results on predicting RUL.   

With the growing development of machine learning techniques and availability of computational resources, neural networks became more and more popular due to their ability to automatically construct features. Among which, Convolutional Neural Networks (CNN) were the first architectures to make a notable advancements due to the fact that CNN can learn local, spatial structure within data.  In this work \cite{Babu2016} CNN architecture consisting of two layers of 1D convolutions following 1D pooling layer and fully connected final layer was applied to segmented multi-variate time series input data. The results obtained in this research proved that CNN approach can outperform classical machine learning methods. Later, \cite{LI20181} introduced slightly different CNN architecture, consisting of five 2D convolutional layers, each except the last with ten 1D kernels, which got even higher results. Such architecture was aimed to capture longer temporal structure due to increased depth of CNN and thus bigger receptive field.  

However, CNNs are not designed to capture long temporal dependencies in data, to obtain a relatively large receptive field CNN should be deep. The second drawback of CNN in relation to RUL prognostics is that temporal dependencies learned by CNN are not causal, meaning that both previous and following time steps are available for CNN kernel at any particular time step. Due to this fact, Recurrent Neural Networks (RNN) showed better performance than CNNs. RNNs were designed to capture long temporal dependencies by the ability of remembering and updating information about previous time steps in the hidden state. This work \cite{Zheng2017} proposed LSTM model for RUL estimation which outperforms both classical machine learning methods as well as CNNs. As further development this paper suggests using CNN as feature extractor before LSTM to reduce noise and frequency of input features. Another work \cite{ELSHEIKH2019148} enhances LSTM approach by proposing bidirectional LSTM to extract more information from sequential sensor data.  

Recent developments in Graph Neural Networks (GNN) have been reflected in their application to RUL prediction tasks. In contrary to sequential and hierarchical structure of common neural network architectures, GNN allows more flexible and complex relationships between NN structures. In this study \cite{GNMR2020} Gated Graph Neural Network (GGNN) \cite{GatedNN2015} was proposed in which subsets of features were represented as graph nodes, and each edge models causal relations between those subsets. In this way the model was capturing the complex structure of the equipment.  

Most deep learning architectures treat each feature vector with equal importance, not considering the extent by which this vector contribute to predicted values. In order to focus on the features which contribute the most to the prediction the Attention mechanism was introduced and widely applied to different domains, such as natural language translation, computer vision many other fields of study.  

The Attention mechanism was widely adopted and combined with many existing RUL prediction architectures as well as used as stand alone approach. In  \cite{RNNATN2019} the attention mechanism was introduced which weights LSTM outputs of each time step and combines them with final step output. The LSTM model with introduced Attention mechanism outperforms pure LSTM model. In the following work \cite{AGCNN2021}, on contrary, the Attention mechanism was applied to the input features to weight each feature according learned importance to enhance representativeness of input data.

The success of the attention-based models led to its further development and appearance of more advanced self-attention and multi-head attention mechanisms and architectures based mainly on them such as Transformers.  This work \cite{MDSA2022} shows that sequentially applying Multi-Head Attention on features and then on sequences before LSTM layer can produce outstanding results by enhancing information retrieval from input features.  Another study \cite{Zhang2022} obtained similar results by applying modified Transformer architecture to multi-variate time series.  In particular, the modified part was Encoder block of the Transformer, sensor encoder and time step encoder of the same architecture, processing inputs in parallel were introduced as part of this block to extract temporal and spatial features. After extracting, both features are merged together to represent information from both aspects.

The growing demand in NN architecture which can capture long temporal dependencies without drawbacks of RNNs, such as computational complexity due to sequential input processing and vanishing gradients results in invention of Temporal Convolutional Networks \cite{TCN2018}. TCN consists of dilated, causal convolutions, meaning that no information leaks from past time steps to future. The same paper showed that TCNs outperforms RNNs across a broad variety of sequence modeling tasks. Application of TCN to RUL prediction is described in \cite{DATCNN2021}, a proposed consists of spatial and temporal attention blocs and TCN as feature extractors. 
Another work \cite{BiGRUTCN2022} uses TCN in parallel with bidirectional Gated Recurrent Unit (GRU) after attention block as feature extractor.
As further development of the TCN ideas, Sample Convolution and Interaction Network (SCINet) was introduced to address some of TCN limitations. The application of SCINet together with LSTM feature extractors is described in \cite{Zhevnenko2023}.

Another approach is based on modified Variational Autoencoder (VAE), the idea behind this approach is to use the latent representation of encoded input sensor signals for RUL prediction. In this research \cite{COSTA2022108353} authors substitute the decoder part of VAE by Regressor, the loss function was modified accordingly. This forced the latent representation of input signal to be representation of the system rate of deterioration. The benefit of this approach is that not only the model is highly accurate but also the latent space obtained from input signals is interpretable.

Table \ref{table: CMAPSS} shows the results comparison of different methods on C-MAPSS dataset.
\begin{table}[h!]
	\centering
    \resizebox{\textwidth}{!}{    
\begin{tabular}{cccccccccc}
    \toprule
    	\multirow{2}{*}{Methods} & \multirow{2}{*}{Year}
        & \multicolumn{2}{c}{FD001} 
        & \multicolumn{2}{c}{FD002}
        & \multicolumn{2}{c}{FD003}
        & \multicolumn{2}{c}{FD004}\\
   \cmidrule(r){3-10} 
    & & RMSE  & Score  & RMSE  & Score & RMSE  & Score & RMSE  & Score  \\
    \midrule
    CNN \cite{Babu2016} & 2016 & 18.448  & 1286 &  30.294 & 13570 & 19.817 & 1596 &  29.156  & 7886    \\
    LSTM \cite{Zheng2017} & 2017 & 16.14  & 338 &  24.49 & 4450 & 16.18 & 852 &  28.17  & 5550    \\
    DCNN \cite{LI20181} & 2018 & 12.61  & 274 &  22.36 & 10412 & 12.64 & 284 &  23.31  & 12466    \\
    Attn-DLSTM \cite{RNNATN2019} & 2019 & 12.22  & - &  23.16 & - & 15.61 & - &  28.30  & -    \\
    GNMR \cite{GNMR2020} & 2020 & 12.14  & 212 &  20.85 & 3196 & 13.23 & 370 &  21.34  & 2795    \\
    AGCNN \cite{AGCNN2021} & 2021 & 12.42  & 226 &  19.43 & 1492 & 13.39 & 227 &  21.50  & 3393    \\
    DA-TCN \cite{DATCNN2021} & 2021 & 11.78  & 229 &  16.95 & 1842 & 11.56 & 257 &  18.23  & 2317    \\
    RVE \cite{COSTA2022108353} & 2022 & 13.42  & 323 &  14.92 & 1379 & 12.51 & 256 &  16.37  & 1845    \\
    MDSA \cite{MDSA2022} & 2022 & 11.43  & 209 &  \textbf{13.32} & 1058 & 11.47 & 187 &  \textbf{14.38}  & 1618    \\
    DAST \cite{Zhang2022} & 2022 & 11.43  & \textbf{203} &  15.25 & 924 & 11.32 & \textbf{155} &  18.36  & \textbf{1490}    \\
    TCN-BiGRU \cite{BiGRUTCN2022} & 2022 & \textbf{11.17}  & 207 &  14.06 & \textbf{842} & \textbf{10.42} & 207 &  16.34  & 1498    \\
    Time-feature interaction model \cite{Zhevnenko2023} & 2023 & 11.59  & 208 &  - & - & 10.9 & 187 &  -  & -    \\
    \bottomrule
\end{tabular}}
\caption{Results comparison of different methods on C-MAPSS dataset.}
\label{table: CMAPSS}
\end{table}

\subsection{Latent Space Representation}

A latent representation of the input signal that is understandable by humans may be used to meet the requirement of interpretability. To obtain such a representation, the desired model must ensure that the latent space is both representative of the equipment condition and human-interpretable. That can be done by reducing the dimensionality of latent space of modified VAE model as shown in \cite{COSTA2022108353}. While being a very promising method, replacing the decoder with a regressor hinders the ability of the model to learn patterns and changes of input sensor data as latent space encodings. 

An examination of the association between input signal data shifts and latent space disentanglement demonstrated in \cite{EEG2022}, shows that the latent space representation may serve as a useful source of information about the input signal. To measure the disentanglement in the latent space the graph-based topological metric was introduced. In addition, the results in \cite{EEG2022} demonstrated that VAE models trained with encoder, decoder, and regressor or classifier blocks under fully-supervised conditions performed better than those trained with encoder weights fixed during fine-tuning. 

In this article \cite{CHROMAVAE2022}, the authors provide an empirical result indicating that deep neural networks preferentially encode shortcuts because they are the most effective compression of data that is highly predictive of training label predictions. The proposed method to overcome this behavior is to use this similar preference in a generative classifier to discover a encoding that is invariant to shortcuts. The key idea is to back-propagate the classifier's loss through a latent subspace while reconstructing with the complete latent space. This pushes the model to minimize classification loss by embedding the shortcut in the latent subspace and isolating it from the complementary latent space, which is capable of learning shortcut-free representation.

The method of learning disentangled representations proposed in \cite{LOSTLS2022} is largely based on forcing the model to learn representations by propagating the original and transformed inputs through the same encoder to obtain latent embeddings and then transforming these two embeddings in latent space. The altered latent embedding acquired is then utilized to reconstruct the required output. The authors measured the degree of disentanglement of the latent space using the DCI metric. This measure gives a set of regression weights between ground truth factors and latent variables.

In \cite{PROTOVAE2022}, an alternative method of learning explainable VAE is proposed. The authors suggest a novel VAE architecture in which the set of learned prototypes is compared with a latent space vector to obtain similarity scores, and the similarity scores are then passed through a classifier to obtain the true class prediction. In this work the model is trained end-to-end to learn both the prototypes in the latent space and the projection back to the input space. Regularization forces the prototype of each class to be orthonormal to each other in order to promote intra-class variation and avoid the learned prototypes from collapsing to the class center.

Another work \cite{ROTVAE2022} propose a model which separates the latent representation of input image data into rotation, translation and an unstructured semantic vector. The spatial decoder is then used to create images that are conditioned on the latent variables using sampled translation, rotation, and content vectors. Hence, by structurally partitioning the picture generating factors into semantic, rotation, and translation components, the model is able to learn semantic object representations that are invariant to pose and location from images distorted by these transformations.

In this study \cite{kim2022unsupervised}, the authors propose using a FACTOR-VAE architecture to maintain a disentanglement latent representation that functions as a conditional image label for the reverse diffusion process. Disentanglement of latent variables is achieved by adjusting the weight term for the Kullback–Leibler divergence loss term in the VAE block to a value greater than one. The findings obtained from the dSprites and CelebA datasets indicate that the proposed model employs a conditioning structure, therefore the disentanglement constraint has negligible effect on the performance of image production.

The authors of this paper \cite{vahdat2021scorebased} propose applying the diffusion process to the latent representation of the input data rather than the raw input. The VAE is initially trained with a normal prior, which is subsequently replaced by a score-based generative model that is trained simultaneously with the VAE. In addition, a new training objective is provided based on the cross entropy between the encoder distribution and the score-based generative model (SGM) prior. 

This paper \cite{li2022diffusionlm} proposes a controllable diffusion language model (Diffusion-LM) based on the sequence of continuous latent variables instead of discrete text. Diffusion-LM modifies the basic diffusion model in two significant ways. The first change is the employment of an embedding function to translate discrete text into a continuous space, and the second change is the creation of a mechanism to round continuous vectors back into discrete words. To address these adjustments, the authors suggest a comprehensive training goal for learning embeddings and training and decoding time approaches to facilitate rounding. In addition, the work introduces a re-parameterization of the objective function to emphasize modeling the structure of the anticipated continuous vectors, as well as a decoding approach known as the clamping trick to enhance the model's capacity to output text.

In this work a regularization method for variational autoencoders (VAEs) called consistency regularization (CR-VAE) is proposed \cite{sinha2021consistency}. The approach aims to enforce the consistency of the encoder in VAEs, ensuring that the encoder provides similar latent representations for the original data and its augmented versions. The enhanced version is a semantics preserving transformation, so VAE preserves its transformation into the same space and forces it to have the same posterior distribution. The CR-VAE regularizes the VAE objective function by adding a regularization term that penalizes the divergence between the approximate posterior distributions of the original data and its augmentations. The regularization term only affects the encoder and can be easily approximated using Monte Carlo methods. The proposed method is applicable to various VAE variants and can improve the quality of learned representations. 

The problems that come with learning disconnected manifolds is discussed in this this study \cite{dey2020topo}, which  suggests to solve the aforementioned problem by using a generative adversarial network (GAN). The proposed method consists of two steps: optimizing the topology of a latent space by utilizing the persistent homology (PH) of the Vietoris–Rips (VR) complex, and using a GAN to learn a homeomorphism between the distributions of the original data samples and the samples in the latent space. Spectral normalization is used to ensure that the GAN generator is 1-Lipschitz continuous, and signature loss is employed to compare the topology of the latent space to that of the original data manifold. The method has been tested on both vanilla GAN and WGAN-GP architectures, and it estimates the density of unconnected supports effectively.

The paper \cite{duarte2022contrastive} suggests a way to separate a GAN's hidden space into its appearance and its structure. A latent autoencoder is used to learn the features. It has an encoder that picks up on appearance and structural features and a decoder that puts the input back together from the features that have been separated. The authors teach the encoder to separate the features by giving it a video-based contrastive learning goal. Specifically, they use contrastive losses to learn appearance and structural features separately. They generate synthetic videos to obtain large amounts of training data and use image augmentation techniques to obtain positive samples for the contrastive structural loss. The paper also includes auxiliary losses to help in training, including cyclic losses to ensure that the encoder and decoder can reconstruct the original input.

Neighborhood Reconstructing Autoencoder (NRAE) is proposed in \cite{lee2021neighborhood}, which is a type of autoencoder that preserves the local geometry of the original data by approximating the decoder in the same region. The NRAE employs a neighborhood reconstruction loss that quantifies the difference between a data point's neighborhood and its reconstruction in the decoded manifold. The set of points surrounding a given point is referred to as its neighborhood, and decoder reconstruction is performed using a local quadratic (or linear) approximation. This concept improves the robustness of autoencoder training by facilitating the learning of the correct geometry and reducing noise sensitivity.

An approach for semi-supervised anomaly detection (SSAD), the task of determining whether or not a sample originates from a normal distribution or not is discussed in \cite{daniel2021deep}. Using deep latent variable models, the research proposes max-min likelihood VAE (MML-VAE) and dual-prior VAE (DP-VAE) as two distinct techniques for approaching the normal distribution. MML-VAE increases the likelihood of normal samples and decreases the likelihood of outliers by using a single encoder for both types of data, whereas DP-VAE utilizes distinct priors for normal and outlier samples. The effectiveness of the authors' recommended methods is demonstrated through experiments.

To address the limited expressivity of prior distributions in probabilistic generative models, this paper \cite{aneja2021a} proposes a noise contrastive prior (NCP). The NCP is defined as the product of a prior distribution and a reweighting factor, which can be trained into a binary class using noise contrastive estimation (NCE). The proposed method aims to enhance the correspondence between the prior and aggregate posterior distributions. In the first stage, the base prior is trained with a variational autoencoder (VAE), and in the second stage, the reweighting factor is trained with an NCE. Training the reweighting factor involves minimizing the cross-entropy loss between samples drawn from the base prior and the aggregate posterior